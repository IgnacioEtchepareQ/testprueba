# -*- coding: utf-8 -*-
"""Entrega_4_Aprendizaje_no_Supervisado_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LaM7WdtE6Qnsz63Bpi6alWGYUzKxOZSl

# Caso Banco “Monopoly/Dormammu”


**Integrantes** 

*   Ignacio Etchepare
*   Diego Ortiz

# Análisis Exploratorio

##  1. Business Understanding

###Contexto:

* El banco Monopoly lleva años atendiendo a la mayoría de chilenos, pero recientemente fue comprada por inversores extranjeros, estos son "Dormammu", y con este nuevo cambio gerencial Dormammu busca conocer además de comprender los diferentes patrones que lleven sus socios, generar nuevas estrategias para captar nuevos clientes de acuerdo con sus fluctuaciones financieras. De acuerdo con lo entregado en el contexto, se pasarán a revisar datos exactos entregados por los informáticos de Monopoly, en donde específicamente entregaron datos en una base de datos con una antigüedad de 12 meses, este aproximadamente tiene 574 variables y 51.124 registros..



* Objetivo : conocer la cartera de clientes

## 2. Data Understanding

A continuación, se verán todas las importaciones de las diferentes librerías que se utilizaran para esta fase de análisis, en donde se pueden apreciar las de panda, numpy, entre otras. Además, se utilizará la carga de la base de datos proporcionada por la empresa “Monopoly”.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.impute import KNNImputer
plt.Axes.axes
plt.boxplot
# Encodeo
from sklearn import preprocessing
# Normalización y estandarización
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.preprocessing import OneHotEncoder
from sklearn.preprocessing import LabelEncoder

from sklearn.svm import SVC 
from sklearn.metrics import accuracy_score
import numpy


# %matplotlib inline

df = pd.read_csv('https://media.githubusercontent.com/media/blacknightray145/bank/master/Base_clientes_Monopoly.csv?token=ATVXZDP6JXNGF3CFUUO6ZFDDEU5B2')

df

#Se elimina la ultima columna, ya que es un contador de columnas.
df = df.iloc[:, :-1]

#Se Procederá a eliminar el header original, debido a que la primera fila del df corresponden a números uno, lo que imposibilita el trabajo con este DataFrame. 
d=df.rename(columns=df.iloc[0]).drop(df.index[0])

#@title DataFrame 
d

"""## El dataFrame presenta todos sus datos de tipo object. """

d.dtypes

"""Análisis básico:
1. Número de Clientes
2. Agrupación por Sexo
3. Frecuencia absoluta de Edad
4. Regiones a los cuales pertecen los clientes
"""

# 1. Cantidad de Clientes
d['Id'].count()

"""______________________________________________________________________________________________"""

#Cantidad de clientes Hombre y Mujeres
d['Sexo'].value_counts()

#Se transforma columna Edad de tipo object a numerico (float64)
edad = d['Edad'].astype('float64')
#Edad maxima de los clientes
edad.max()

#Edad minima de los clientes
edad.min()

#Frecuencia absoluta de la columna edad
edad.value_counts().sort_index()

#Se transforma columna Region de tipo object a numerico (float64)
region = d['Region'].astype('float64')

region.value_counts().sort_index()

"""CONCLUSIÓN : Para empezar a conocer a los clientes de “Monopoly” se da a conocer que este banco presenta una cantidad de 51124 clientes y en donde los clientes pertenecen a una de las 13 regiones.

El sexo que presenta los clientes es 27410 son hombres y 23713 son mujeres. También los clientes se encuentran en un rango desde los 9 años hasta los 104 años.

Análisis de Productos:

1. Cantidades de cuentas por clientes 
2. Cantidad de tarjetas de crédito por cliente
3. Rango de cupos de tarjetas de crédito
4. Antiguedad en meses de los clientes
5. Tipos de producto por cliente
"""

# 1. Cantidades de cuentas por clientes 

d['Cuentas'] = d['Cuentas'].astype('float64')
d['Cuentas'].describe()

# 2. Cantidad de tarjetas de crédito por cliente
d['TC'] = d['TC'].astype('float64')
d['TC'].describe()

# 3. Rango de cupos de tarjetas de crédito internacional
d['CUPO_MX'] = d['CUPO_MX'].astype('float64')
d['CUPO_MX'].describe()

# 3. Rango de cupos de tarjetas de crédito nacional
d['CUPO_L1'] = d['CUPO_L1'].astype('float64')
d['CUPO_L1'].describe()

# 4. Antiguedad en meses de los clientes
d['Antiguedad'] = d['Antiguedad'].astype('float64')
d['Antiguedad'].describe()

#5. Tipos de producto por cliente Debito
d['Debito'] = d['Debito'].astype(int)
d['Debito'].value_counts()

# Tipos de producto por cliente Cuenta Corriente
d['Ctacte'] = d['Ctacte'].astype(int)
d['Ctacte'].value_counts()

# Tipos de producto por cliente Credito Hipotecario
d['Hipotecario'] = d['Hipotecario'].astype(int)
d['Hipotecario'].value_counts()

# Tipos de producto por cliente Internauta
d['Internauta'] = d['Internauta'].astype(int)
d['Internauta'].value_counts()

"""CONCLUSIÓN: En el Banco Monopoly sus clientes pueden tener entre 1 a 5 cuentas bancarias. Además, los clientes también tienen la posibilidad de tener Tarjetas de crédito, en donde puedes optar a tener una cantidad de 12 tarjetas como máximo. Estas tarjetas de créditos tienen cupo para compras internaciones, en donde este cupo puede ser desde los 0 hasta $21.540.000.
Además, los clientes en el banco Monopoly presentan un rango de antigüedad de sus clientes desde los 6 hasta los 324 meses.
Finalmente, el banco  para sus las variables de consumo, débito, cuentas corriente, crédito hipotecario e internauta utiliza indicadores numéricos los cuales les permiten saber si tienen ciertos servicios, estos indicadores presentan el siguiente significado:
- 1=Poseedor del servicio
- 0=No presenta el servicio

## 3. Data Preparation

Las variables de sexo, renta y región presentan NaN o missing values. Esto afecta en conjunto con la normalización de los datos, generando problemas a la hora de la presentación de reportes o incluso mostrando una data que no sea próximo a la realidad. 

*   Cantidad de valores faltantes en Sexo: 1
*   Cantidad de valores faltantes en Región	: 53
*   Cantidad de valores faltantes en Renta: 13365
"""

d.isnull().sum()

d['Region'] = d['Region'].fillna(0)
d['Renta'] = d['Renta'].fillna(d['Renta'].median())

from sklearn.preprocessing import OneHotEncoder

enc = OneHotEncoder(handle_unknown='ignore')
d["Sexo"] = enc.fit_transform(d["Sexo"].to_numpy().reshape(-1, 1)).toarray()

d.isnull().sum()

"""Dado el bajo número de Regiones faltantes, estas se dejan con valor CERO.

Para el valor faltante en SEXO, dado que es un sólo dato, se deja con un valor distinto a H/M, para posterior identificación. (se usará OneHotEncoder).

Para la RENTA, se usará la Media en reemplazo de los NaN (propiedad de la media con respecto al total).

## 4. Escalamiento

Considerar que hay datos que pueden escalarse con StandarScaler y otros, como Renta, con MinMaxScaler. Esto, la relevancia y gran distribución de dicho dato.
"""

# from sklearn.preprocessing import MinMaxScaler

# scaler = MinMaxScaler()

# d[['Renta']] = scaler.fit_transform(d[['Renta']])

d['Renta'].describe()

d['Renta']

"""## 5. Análisis

Correlacionar Edad con Renta.

Histograma de EDAD y respectivo análisis estadístico.

Histograma de clientes por REGION y su respectivo análisis estadístico.

Histogramas de clientes por PRODUCTOs y su respectivo análisis estadístico.

Histograma de clientes por ANTIGUEDAD y su respectivo análisis estadístico.

Detección y análisis de outliers (gráfico de caja).

En el grafico se muestran las diferentes edades con sus respectivas rentas.
"""

d['Edad'] = d['Edad'].astype(int)
d['Renta'] = d['Renta'].astype(int)

plt.scatter(d['Edad'], d['Renta'])

"""En este histograma se puede apreciar que la mayor cantidad de clientes se encuentra en un rango de edad que va desde los 20 a 40 años, donde la mayor frecuencia de clientes esta en los 28 años."""

import matplotlib.pyplot as plot
intervalos = range(min(d['Edad'].astype(int)), max(d['Edad'].astype(int))) #calculamos los extremos de los intervalos

plot.hist(x=d['Edad'].astype(int), bins=80, color='#F2AB6D', rwidth=50)
plot.title('Histograma de edades')
plot.xlabel('Edades')
plot.ylabel('Frecuencia')

plot.show() #dibujamos el histograma

"""En este histograma se puede ver que la mayoria de clientes cuenta con productos bancarios en la region 12, siendo la region numero 3 la con menor cantidad de clientes."""

d['Region'] = d['Region'].astype(int)
plt.figure(figsize=(5,5))
plt.hist(x = d['Region'], bins = 10)
plt.xlabel("Región")
plt.ylabel("Cantidad")
plt.title("Histograma Cantidad de cliente por Región")
plt.show()

d['Debito'] = d['Debito'].astype(int)
plt.figure(figsize=(5,5))
plt.hist(x = d['Debito'], bins = 10)
plt.xlabel("0 = No tiene / 1 Si tiene ")
plt.ylabel("Cantidad")
plt.title("Histograma Cantidad de cliente que tiene o no tiene Tarjeta de Debito")
plt.show()

d['Ctacte'] = d['Ctacte'].astype(int)
plt.figure(figsize=(5,5))
plt.hist(x = d['Ctacte'], bins = 10)
plt.xlabel("0 = No tiene / 1 Si tiene ")
plt.ylabel("Cantidad")
plt.title("Histograma Cantidad de cliente que tiene o no tiene Cuenta Corriente")
plt.show()

"""En este histograma se puede ver que la mayoria de clientes no tiene demasiada antiguedad en este banco, la mayor frecuencia se encuentra en clientes nuevos, con una antiguedad que va desde los 50 hacia abajo """

intervalos = range(min(d['Antiguedad'].astype(int)), max(d['Antiguedad'].astype(int))) #calculamos los extremos de los intervalos

plot.hist(x=d['Antiguedad'].astype(int), bins=60, color='#F2AB6D', rwidth=5)
plot.title('Histograma de antiguedad')
plot.xlabel('Antiguedad')
plot.ylabel('Frecuencia')

plot.show()

fig = plt.figure(figsize =(10, 7)) 
  
plt.boxplot(d['Renta']) 
  
plt.show()

fig = plt.figure(figsize =(10, 7)) 
  
plt.boxplot(d['Antiguedad']) 
  
plt.show()

fig = plt.figure(figsize =(10, 7)) 
  
plt.boxplot(d['Edad'].astype(int)) 
  
plt.show()

d

"""## 6.Conclusiones

En el Banco Monopoly Dormammu, se identifican con un grafico el rango de edades con la renta de los clientes, que podemos apreciar outliers con la edad comenzando desde la edad de 9 hasta los 104 años.

Tambien se identifican a los clientes que posee el Banco en las diferentes regiones del pais.

Tambien se muestra a la cantidad de clientes que tiene o no tiene los diferentes tipos de productos, en este caso "Tarjeta de Debito" y "Cuenta Corriente" 

Se conoce la antiguedad de los clientes que tiene el Banco "Dormammu" se puede ver que la mayoria de clientes no tiene demasiada antiguedad en este banco.

Se crean diferentes graficos de cajas con datos de Renta, Antiguedad y edad, identificando los outiler, la maxima y minima de los datos, con su respectiva media y cuartiles.

# Aprendizaje Supervizado - Clasificación

Selección de columnas.
"""

df_columns = d[["Region", "Renta", "Sexo", "Subsegmento", "Edad", "Adicional","Antiguedad", "CambioPin", 
                 "Consumo", "Debito", "Ctacte", "Cuentas", "Hipotecario", "Internauta", "Monoproducto","TC", "Dualidad",
                 "CUPO_L1", "CUPO_MX", "CUPO_L2", "Col_T12", "ColL1TE_T12", "EeccInt_T12", "EeccNac_T12", "Fac_T12", "FacAI_T12", "FacAN_T12",
                 "FacCCOT_T12", "FacCCPC_T12", "FacCI_T12", "FacCN_T12", "FacCOL_T12", "FacDebAtm_T12", "FacDebCom_T12", "FacPAT_T12",
                 "FlgAct_T12", "FlgActAI_T12", "FlgActAN_T12","FlgActCCOT_T12", "FlgActCCPC_T12", "FlgActCI_T12", "FlgActCN_T12",
                 "FlgActCOL_T12", "FlgActPAT_T12", "PagoInt_T12", "PagoNac_T12", "Txs_T12", "TxsAI_T12", "TxsAN_T12", "TxsCCOT_T12", 
                 "TxsCCPC_T12", "TxsCI_T12", "TxsCN_T12", "TxsCOL_T12", "TxsDebAtm_T12", "TxsDebCom_T12", "TxsPAT_T12", "UsoL1_T12", "UsoL2_T12", "UsoLI_T12", "target"]]
df_columns

# vamos a crear una copia de los datos originales
datos_knn = df_columns.copy()
datos_knn = pd.DataFrame(datos_knn)
datos_knn

datos_knn.isnull().sum()

"""
Reemplazamos todos los NaN a travez del metodo KNN Imputer"""

from sklearn.impute import KNNImputer

knn_imputer = KNNImputer(n_neighbors=2, weights="uniform")

"""Se cambian los datos NaN por la media."""

datos_knn['CambioPin'] = datos_knn['CambioPin'].replace({np.nan : datos_knn["CambioPin"].median()})
datos_knn['CUPO_L1'] = datos_knn['CUPO_L1'].replace({np.nan : datos_knn["CUPO_L1"].median()})
datos_knn['CUPO_MX'] = datos_knn['CUPO_MX'].replace({np.nan : datos_knn["CUPO_MX"].median()})
datos_knn['CUPO_L2'] = datos_knn['CUPO_L2'].replace({np.nan : datos_knn["CUPO_L2"].median()})
datos_knn['Col_T12'] = datos_knn['Col_T12'].replace({np.nan : datos_knn["Col_T12"].median()})
datos_knn['ColL1TE_T12'] = datos_knn['ColL1TE_T12'].replace({np.nan : datos_knn["ColL1TE_T12"].median()})
datos_knn['EeccInt_T12'] = datos_knn['EeccInt_T12'].replace({np.nan : datos_knn["EeccInt_T12"].median()})
datos_knn['EeccNac_T12'] = datos_knn['EeccNac_T12'].replace({np.nan : datos_knn["EeccNac_T12"].median()})
datos_knn['Fac_T12'] = datos_knn['Fac_T12'].replace({np.nan : datos_knn["Fac_T12"].median()})
datos_knn['FacAI_T12'] = datos_knn['FacAI_T12'].replace({np.nan : datos_knn["FacAI_T12"].median()})
datos_knn['FacAN_T12'] = datos_knn['FacAN_T12'].replace({np.nan : datos_knn["FacAN_T12"].median()})
datos_knn['FacCCOT_T12'] = datos_knn['FacCCOT_T12'].replace({np.nan : datos_knn["FacCCOT_T12"].median()})
datos_knn['FacCCPC_T12'] = datos_knn['FacCCPC_T12'].replace({np.nan : datos_knn["FacCCPC_T12"].median()})
datos_knn['FacCI_T12'] = datos_knn['FacCI_T12'].replace({np.nan : datos_knn["FacCI_T12"].median()})
datos_knn['FacCN_T12'] = datos_knn['FacCN_T12'].replace({np.nan : datos_knn["FacCN_T12"].median()})
datos_knn['FacCOL_T12'] = datos_knn['FacCOL_T12'].replace({np.nan : datos_knn["FacCOL_T12"].median()})
datos_knn['FacDebAtm_T12'] = datos_knn['FacDebAtm_T12'].replace({np.nan : datos_knn["FacDebAtm_T12"].median()})
datos_knn['FacDebCom_T12'] = datos_knn['FacDebCom_T12'].replace({np.nan : datos_knn["FacDebCom_T12"].median()})
datos_knn['FacPAT_T12'] = datos_knn['FacPAT_T12'].replace({np.nan : datos_knn["FacPAT_T12"].median()})
datos_knn['FlgAct_T12'] = datos_knn['FlgAct_T12'].replace({np.nan : datos_knn["FlgAct_T12"].median()})
datos_knn['FlgActAI_T12'] = datos_knn['FlgActAI_T12'].replace({np.nan : datos_knn["FlgActAI_T12"].median()})
datos_knn['FlgActAN_T12'] = datos_knn['FlgActAN_T12'].replace({np.nan : datos_knn["FlgActAN_T12"].median()})
datos_knn['FlgActCCOT_T12'] = datos_knn['FlgActCCOT_T12'].replace({np.nan : datos_knn["FlgActCCOT_T12"].median()})
datos_knn['FlgActCCPC_T12'] = datos_knn['FlgActCCPC_T12'].replace({np.nan : datos_knn["FlgActCCPC_T12"].median()})
datos_knn['FlgActCI_T12'] = datos_knn['FlgActCI_T12'].replace({np.nan : datos_knn["FlgActCI_T12"].median()})
datos_knn['FlgActCN_T12'] = datos_knn['FlgActCN_T12'].replace({np.nan : datos_knn["FlgActCN_T12"].median()})
datos_knn['FlgActCOL_T12'] = datos_knn['FlgActCOL_T12'].replace({np.nan : datos_knn["FlgActCOL_T12"].median()})
datos_knn['FlgActPAT_T12'] = datos_knn['FlgActPAT_T12'].replace({np.nan : datos_knn["FlgActPAT_T12"].median()})
datos_knn['PagoInt_T12'] = datos_knn['PagoInt_T12'].replace({np.nan : datos_knn["PagoInt_T12"].median()})
datos_knn['PagoNac_T12'] = datos_knn['PagoNac_T12'].replace({np.nan : datos_knn["PagoNac_T12"].median()})
datos_knn['Txs_T12'] = datos_knn['Txs_T12'].replace({np.nan : datos_knn["Txs_T12"].median()})
datos_knn['TxsAI_T12'] = datos_knn['TxsAI_T12'].replace({np.nan : datos_knn["TxsAI_T12"].median()})
datos_knn['TxsAN_T12'] = datos_knn['TxsAN_T12'].replace({np.nan : datos_knn["TxsAN_T12"].median()})
datos_knn['TxsCCOT_T12'] = datos_knn['TxsCCOT_T12'].replace({np.nan : datos_knn["TxsCCOT_T12"].median()})
datos_knn['TxsCCPC_T12'] = datos_knn['TxsCCPC_T12'].replace({np.nan : datos_knn["TxsCCPC_T12"].median()})
datos_knn['TxsCI_T12'] = datos_knn['TxsCI_T12'].replace({np.nan : datos_knn["TxsCI_T12"].median()})
datos_knn['TxsCN_T12'] = datos_knn['TxsCN_T12'].replace({np.nan : datos_knn["TxsCN_T12"].median()})
datos_knn['TxsCOL_T12'] = datos_knn['TxsCOL_T12'].replace({np.nan : datos_knn["TxsCOL_T12"].median()})
datos_knn['TxsDebAtm_T12'] = datos_knn['TxsDebAtm_T12'].replace({np.nan : datos_knn["TxsDebAtm_T12"].median()})
datos_knn['TxsDebCom_T12'] = datos_knn['TxsDebCom_T12'].replace({np.nan : datos_knn["TxsDebCom_T12"].median()})
datos_knn['TxsPAT_T12'] = datos_knn['TxsPAT_T12'].replace({np.nan : datos_knn["TxsPAT_T12"].median()})
datos_knn['UsoL1_T12'] = datos_knn['UsoL1_T12'].replace({np.nan : datos_knn["UsoL1_T12"].median()})
datos_knn['UsoL2_T12'] = datos_knn['UsoL2_T12'].replace({np.nan : datos_knn["UsoL2_T12"].median()})
datos_knn['UsoLI_T12'] = datos_knn['UsoLI_T12'].replace({np.nan : datos_knn["UsoLI_T12"].median()})
datos_knn

"""Se verifica los tipos de datos"""

cols = datos_knn.columns
datos_knn[cols] = datos_knn[cols].apply(pd.to_numeric, errors='coerce')
datos_knn.dtypes

"""Se realiza una matriz de correlacion para observar las columnas estan relacionadas con la columna target."""

import seaborn as sns
corr_df = datos_knn.corr(method='pearson')

plt.figure(figsize=(40, 40))
sns.heatmap(corr_df, annot=True)
plt.show()

datos_knn_ultimo = datos_knn[["Edad", "Debito", "Ctacte", "Monoproducto", "Dualidad","ColL1TE_T12","EeccNac_T12","FacCOL_T12","FacDebAtm_T12","FacDebCom_T12","FlgActCCOT_T12","FlgActPAT_T12","TxsCCOT_T12","TxsDebAtm_T12","TxsDebCom_T12","UsoL1_T12","target"]]

datos_knn_ultimo

"""#DATOS ENTRENAMIENTO"""

X3 = datos_knn_ultimo.iloc[:, :-1].values
y3 = datos_knn_ultimo['target']

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X3, y3, test_size=0.30)

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

"""#KNN"""

from sklearn.neighbors import KNeighborsClassifier
classifier = KNeighborsClassifier(n_neighbors=5)
classifier.fit(X_train, y_train)

y_pred = classifier.predict(X_test)
y_pred

unique, counts = numpy.unique(y_pred, return_counts=True)

dict(zip(unique, counts))

from sklearn.metrics import classification_report, confusion_matrix
print(classification_report(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

"""#SVC"""

model = SVC(kernel='sigmoid',C=1)
model.fit(X_train, y_train)

predicciones = model.predict(X_test)
predicciones

unique, counts = numpy.unique(predicciones, return_counts=True)

dict(zip(unique, counts))

Y_train_predicted = model.predict(X_test)
print(classification_report(y_test, Y_train_predicted))
print(confusion_matrix(y_test, Y_train_predicted))

"""# Conclusión

En el Banco Monopoly Dormammu se realizo 2 modelos de clasificación, esto para poder predecir que dato del "target" es más exacto, en este caso fue el modelo KNN el cual nos daba como resultado un  precision de 0.91 cuando es 0 y de un 0.16 cuando el valor es 1, en el caso del f1-score 0.94 por lo que es un valor bastante cercano al 1. 

Por el contrario el modelo SVM nos daba como resultado una precisión de 0.91  cuando es un 0 y un 0.18 cuando es un 1, en el f1-score nos da un valor de 0.95 lo cual es más bajo que el KNN. 

También se genero la matriz de correlación para poder ver que columnas nos iban a servir para realizar los modelos. 

La problematica de este caso es que Target esta completamente desbalanceado, lo cual no tenia mucha concordancia con las otras columnas.

#Modelo no supervisado

Para el siguiente modelo se intentará explicar cuantos grupos hay de "buenos" y "malos" pagadores, para esto se creará un dataframe tomando las columnas que mas correlación tengan con la columna "target" segun la matriz de correlaccion creada anteriormente.
Se tomarán las siguientes columnas:
* Edad
* Renta
* Ctacte
* Debito
* Monoproducto
* TxsDebAtm_T12
* FacDebAtm_T12
* FacDebCom_T12
"""

datos_MNS = datos_knn[["Edad","Renta", "Ctacte","Debito","Monoproducto","TxsDebAtm_T12","FacDebAtm_T12","FacDebCom_T12"]]
datos_MNS

"""Vemos las caracteristicas de los datos, para asegurarnos que sean todos de tipo float64

"""

datos_MNS.info()

"""Cambiamos los int64 a float64"""

datos_MNS['Edad'] = datos_MNS['Edad'].astype('float64')
datos_MNS['Renta'] = datos_MNS['Renta'].astype('float64')
datos_MNS['Ctacte'] = datos_MNS['Ctacte'].astype('float64')
datos_MNS['Debito'] = datos_MNS['Debito'].astype('float64')
datos_MNS['Monoproducto'] = datos_MNS['Monoproducto'].astype('float64')

datos_MNS.info()

datos_MNS.head()

"""Analizamos los promedios, minimos y maximos de los valores del conjunto de datos  """

datos_MNS.describe()

"""Como existe mucha diferencia entre los promedios de los datos procedemos a normalizarlos para que estén dentro del mismo rango

"""

from sklearn import preprocessing

datos_norm = preprocessing.Normalizer().fit_transform(datos_MNS) #(datos_MNS-datos_MNS.min())/(datos_MNS.max()-datos_MNS.min())
x = datos_norm.copy()

"""# Búsqueda de la cantidad óptima de clusters
Una vez normalizados los datos, se calculará cual es la cantidad optima de clusters. 

Para esto importaremos la libreria de Kmeans
"""

from sklearn.cluster import KMeans

wcss = []

for i in range(1, 11):
  kmeans = KMeans(n_clusters=i,init='k-means++', max_iter=300, n_init=10)
  kmeans.fit(x)
  wcss.append(kmeans.inertia_)

"""Graficamos los resultados de WCSS para formar el codo de Jambú"""

plt.figure(figsize=(15,6))
plt.plot(range(1,11), wcss)
plt.title("Codo de Jambú")
plt.xlabel("Número de clusters")
plt.ylabel("WCSS")
plt.show()

"""Como muestra el grafico, el numero ideal de clusters son 3

# Aplicamos el metodo K-means
con el numero de clusters ya definidos aplicamos el modelo k-means
"""

algoritmo = KMeans(n_clusters = 3,init='k-means++', max_iter=300, n_init=10) #creacion del modelo
algoritmo.fit(datos_norm)#aplicamos el modelo al conjunto de datos

"""Obtenemos lo que son los centroides y etiquetas del modelo"""

centroides,etiquetas = algoritmo.cluster_centers_,algoritmo.labels_

"""# Vizualizamos los clusters que se formaron 
Para esto aplicaremos el analisis de componentes principales (PCA)
separando en dos componentes principales para asi lograr crear un grafico en  dos dimensiones. Tanto como a los datos como a los centroides.
"""

from sklearn.decomposition import PCA

modelo_pca = PCA(n_components = 2)
modelo_pca.fit(x)
pca = modelo_pca.transform(x) 

#Se aplicar la reducción de dimsensionalidad a los centroides
centroides_pca = modelo_pca.transform(centroides)

"""Procedemos a la creacion del grafico """

colores = ['blue', 'red', 'green']
colores_cluster = [colores[etiquetas[i]] for i in range(len(pca))]
plt.figure(figsize=(15,12))
plt.scatter(pca[:, 0], pca[:, 1], c = colores_cluster, 
            marker = 'o',alpha = 0.4)
plt.scatter(centroides_pca[:, 0], centroides_pca[:, 1],
            marker = 'x', s = 100, linewidths = 3, c = 'black')

plt.show()